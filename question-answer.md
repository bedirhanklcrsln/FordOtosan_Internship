# Freespace Segmentation with Fully Convolutional Neural Network (FCNN)  
  
    	
### *Machine Learning*
Machine learning is learning the algorithm by using the data it has.
### *Unsupervised vs Supervised learning difference*  
Both use dataset. Unsupervised Learning doesn't need the tags of the data.
### *Deep Learning*
It is a subfield of machine learning. It uses the labeled data to model the data and learn the data pattern.
### *Neural Network*
It is a machine learning algorithm that works like a human brain.
### *Convolution Neural Network*
It is a deep learning algorithm. it increases the accuracy of object detection by filtering the image.  
Advantages over NN: high accuracy , weight sharing.
### *Segmentation Task in Neural Network*
Segmentation classifies the pixels of the image and divides it into regions and defines the boundaries of the object in the image.
It is supervised
### *Classification Task in Neural Network*
Classification is the classification of the image according to the object in the image , it is supervised.
### *Comparing Classification and Segmentation*
Classification gives class to the image. segmentation classifies parts of the image
### *Data and Dataset difference*
Data is processed or unprocessed information. A dataset is a collection of data collected for a specific purpose.
### *Difference between Supervised and Unsupervised learning in terms of Dataset*
Supervised learning uses dataset but Unsupervised does not use dataset.
### *Color Space*
Color space is a defined range of colors
### *RGB*
It is the digital combination of red, blue and green colors with various proportions
### *In python , can we transform from one color space to another?*
Yes , we can with cvtColor() function
### *Popular library for image processing*
OpenCV
OpenCV is one of the most popular image-processing libraries. It is used for implementing computer vision algorithms and performing machine learning and image processing. In addition, it is available for free and is open-source
### *Computational Graph*
A computational graph is a directed graph where the nodes correspond to operations or variables.They are a form of directed graphs that represent a mathematical expression.
### *Tensor*
Tensor is a mathematical object that generalizes scalars, vectors, and matrices into higher-dimensional spaces.
### *One Hot Encoding*
One hot encoding is a way of representing categorical values in a numerical way
### *CUDA programming*
CUDA is a parallel computing platform and programming model developed by NVIDIA for general computing on graphical processing units (GPUs).
### *Difference CNN and FCNN*
A fully connected neural network is a neural network where each neuron is connected to every neuron in the previous layer. In contrast, a convolutional neural network (CNN) is a neural network where one or more of the layers employs a convolution as the function applied to the output of the previous layer.
### *Different layers on CNN*
convolutional layers, pooling layers, and fully-connected (FC) layers.
### *Activation funciton*
Decides whether a neuron should be activated or no.The softmax function is often used as the last activation function of a neural network to normalize the output of a network to a probability distribution
### *Parameters*
In neural networks, parameters are the weights of the connections between neurons.
### *Hyperparameters*
Hyperparameters are parameters whose values are set before starting the model training process
### *Validation Dataset*
Validation dataset tells us how well the model is learning and adapting,
### *Epoch*
Epoch is refers to one cycle through the full training dataset.
### *Batch*
Batch is a subset of the dataset that the model uses to update the parameters at each iteration during training.
### *Iteration*
Iteration is a repetition of something
example : prime number determination
### *Cost Function*
Cost function  calculates the performance of the machine learning model
### *Optimizers purpose*
In NN , optimizers purpose is reduce loss
### *Batch Gradient Descent*
Batch Gradient Descent calculates over the entire training set at each step
### *Stochastic Gradient Descent* 
Stochastic Gradient Descent calculates with a random value in the training set at each step
Stochastic Gradient Descent is faster and less computationally expensive than Batch Gradient Descent
### *Backpropogation*
Backpropogation is the algorithm that works to test for errors from output nodes to input nodes

